{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from imread import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager, rc\n",
    "font_fname = '/Library/Fonts/AppleGothic.ttf'\n",
    "font_name = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "rc('font', family = font_name)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter; twitter = Twitter()\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_reviews = open('apmall_prd_reviews.txt', 'r')\n",
    "reviews = prd_reviews.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "for re in reviews:\n",
    "    if len(re) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        text_only = re.split(\" | \")[5][:-1]\n",
    "        sent.append(text_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only N, Adj, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for se in sent:\n",
    "    tag = twitter.pos(se, norm = True, stem = True)\n",
    "    im = [i for i in tag if i[1] == \"Noun\" or i[1] == \"Adjective\" or i[1] == \"Verb\"]\n",
    "    result += im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in result:\n",
    "    words.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(words)\n",
    "fdist_common = fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하다', 15298), ('좋다', 11779), ('사용', 4662), ('구매', 4440), ('같다', 4350)]\n",
      "7647\n",
      "하다\n"
     ]
    }
   ],
   "source": [
    "print(fdist_common[:5])\n",
    "print(len(fdist_common))\n",
    "print(fdist_common[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = []\n",
    "for word, freq in fdist_common:\n",
    "    top_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['하다', '좋다', '사용', '구매', '같다', '있다', '제품', '자다', '이니스프리', '것', '쓰다', '되다', '않다', '때', '피부', '바르다', '이다', '향', '보다', '써다', '없다', '저렴하다', '더', '크림', '들다', '구입', '거', '가격', '사다', '순하다', '촉촉하다', '배송', '괜찮다', '추천', '화장', '느낌', '좀', '되어다', '만족하다', '해보다', '생각', '재다', '수', '자극', '쓸다', '받다', '마음', '많다', '이', '적당하다', '처음', '해봤다', '솜', '정말', '또', '용량', '편하다', '여름', '용', '건조하다', '저', '자주', '일', '해주다', '감사하다', '라인', '아니다', '흡수', '싶다', '아주', '쓰기', '효과', '빠르다', '무난', '로션', '그린티', '이번', '부드럽다', '스킨', '다른', '항상', '조금', '오다', '그렇다', '주문', '타입', '보고', '성분', '얼굴', '나오다', '할인', '티슈', '행사', '클렌징', '넘다', '팩', '요', '다음', '한번', '포인트']\n",
      "7647\n"
     ]
    }
   ],
   "source": [
    "print(top_words[:100])\n",
    "print(len(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove formal_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "rm_pos = [\"Punctuation\", \"Josa\", \"Modifier\", \"KoreanParticle\", \"Suffix\", \"Determiner\"]\n",
    "\n",
    "for se in sent[:30]:\n",
    "    tag = twitter.pos(se, norm = True, stem = True)\n",
    "    im = [i for i in tag if i[1] not in rm_pos]\n",
    "    result += im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in result:\n",
    "    words.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(words)\n",
    "fdist_common = fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = []\n",
    "for word, freq in fdist_common:\n",
    "    top_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['하다', '좋다', '토너', '닦다', '구매', '사용', '순하다', '없다', '자극', '있다', '이니스프리', '같다', '괜찮다', '저렴하다', '피부', '각질', '제거', '제품', '너무', '쓰다', '토용', '되다', '것', '청보리', '해봤다', '그냥', '스킨', '필링', '구입', '써다', '해주다', '거', '자다', '배송', '보다', '느낌', '않다', '몰다', '무난', '수', '후', '사다', '토로', '효과', '쓰기', '화장', '솜', '이다', '사보다', '세안', '용도', '더', '용량', '평이', '해보다', '깔끔하다', '맞다', '아직', '안', '때', '많다', '케어', '전혀', '한번', '많이', '그렇다', '개인', '가볍다', '적다', '바르다', '원래', 'ap', '생각', '도', '싶다', '보고', '받다', '해', '내주다', '알아보다', '요', '바로', '적당하다', '추천', '맘', '들다', '기대하다', '크다', '믿다', '아모레퍼시픽', '상품', '샘플', '주다', '암튼', '행사', '입소', '이자', '아이템', '마침', '중이']\n"
     ]
    }
   ],
   "source": [
    "print(top_words[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
